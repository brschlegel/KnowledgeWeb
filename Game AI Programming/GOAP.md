# Goal Oriented Action Programming
GOAP is an older architecture for AI programming that involves mapping a plan to satisfy a goal at runtime using atomic actions and a world state. Actions know what preconditions need to be met, as well as what effect they have on the world state. Planning starts by getting the current world state, and making a desired world state from that current world state. Starting from the end of the plan, a graph is formed by taking each action, and connecting it with the actions that satisfy its preconditions, doing this recursively gives a graph, which is then searched for a line that takes the current world state to the desired world state.
## Benefits
Adding actions very quick and very easy. Because all connections are determined at runtime, all that's neccesary is creating a new action. Compared to a finite state machine, where all connections to every other action must be atleast implicitly considered, its quite nice. Feeding an agent goals instead of actions to take can also be simpler, for example you can tell an agent to attack the player, rather than worrying about if the agent has a weapon, where they are in relation to the player, etc.
## Use Cases
I don't see this talked about much, but its important for the agent to be relatively constrained to get the full benefits of GOAP. The awesome part of GOAP is that the agent figures out the how, you just need to supply the what. If the how isn't very complex, then you are fighting with alot of the cons, without utilizing many of the benefits. This is the main reason that [[ThatDamnGoat]] was a bad fit for the architecture.
## Cons
Man this shit is hard. Because the agent figures out the how, theres alot of time where the path taken isn't super clear. In addition, it means its fairly difficult to get some hooks when you want greater control of the agent. It's hard to test, it breaks all the time. When I mentioned that I did some work with GOAP in the Toys For Bob interview, they chuckled and mentioned that while GOAP is interesting, when you want something to work you do behaviour trees. When originally researching GOAP, I wondered why there weren't more widespread adoption of GOAP, and after my experience on [[ThatDamnGoat]], I understand why. It's too complex for any added benefits, and most AIs don't need that complex or unpredictable behaviour.